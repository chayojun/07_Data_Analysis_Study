# 소개

**EDA(Exploratory Data Analysis)** 란 결측치 및 이상치를 탐지하여 **전처리 방향을 결정**하고,
통계 요약 및 시각화를 통해 데이터의 분포, 변수 간 관계 등 **핵심 특성을 파악하는 과정**이다.

# 데이터 분석 절차 및 고려사항

## 1. 데이터 불러오기

* 데이터 불러오는 함수: `pd.read_csv()`, `pd.read_excel()`, `pd.read_spss()` 
    - `pd.read_csv()`: 
        - 프로젝트 내에 있는 csv파일을 <b>Pandas</b>의 <b>DataFrame(행렬 데이터)</b>로 불러올 때 사용하는 <b>pandas</b> 함수이다.
        -  `pd.read_csv()`의 옵션:  
            - `sep`: CSV 파일의 열이 기본 구분자인 쉼표<b>( , )</b>가 아니라 <b>탭(tab)</b> 등 다른 구분자로 되어 있을 경우 사용한다.탭으로 구분된 파일을 읽을 때는 `sep='\t'`로 지정한다.
            - `encoding`: CSV 파일의 문자 인코딩 방식을 지정한다. 
                - (예: `utf-8`, `cp949` 등)
            - `header`: 파일에 열 이름(헤더)가 없을 경우 `header=None`으로 지정한다.
            - `names`: 열 이름을 직접 지정할 때 사용하며, 보통 `header` 옵션과 함께 사용한다.
                - (예: `names=['A','B','C']`)
            - `usecols`: 특정 열만 선택해서 불러올 때 사용한다. 
                - (예: `usecols=['A','C']`)
            - `na_values`: 특정 값을 <b>결측치(NaN)</b> 로 처리하도록 지정한다. 
                - (예: `na_values=['NA','missing']`)
            - `skiprows`: 파일의 앞부분에서 특정 행들을 건너뛸 때 사용한다. (숫자나 리스트 지정 가능)
            - `index_col`: 불러온 데이터에서 특정 열을 행 인덱스로 지정한다.
    - `pd.read_excel()`: 
        - 프로젝트 내에 있는 excel파일을 <b>Pandas</b>의 <b>DataFrame(행렬 데이터)</b>로 불러올 때 사용하는 <b>pandas</b> 함수이다. 공공기관이나 보험 관련 데이터에서 자주 사용되는 파일 형식이며,
        Jupyter Notebook에서 Excel 파일을 읽기 위해서는 `openpyxl` 라이브러리를 설치해야 한다. 
            - (예: `uv add openyxl`)
        - `pd.read_excel()`의 옵션:
            - sheet_name: 여러 개의 시트 중에서 불러올 시트를 지정한다. (기본값은 첫 번째 시트)
            - header:  파일에 열 이름(헤더)가 없을 경우 `header=None`으로 지정한다.
            - usecols: 특정 열만 선택해서 불러올 때 사용한다. 
                - (예: `usecols=['A','C']`)
            - na_values: 특정 값을 <b>결측치(NaN)</b> 로 처리하도록 지정한다. 
                - (예: `na_values=['NA','missing']`)
    - `pd.read_spss()`:
        - 프로젝트 내에 있는 SPSS 파일을 <b>Pandas</b>의 <b>DataFrame(행렬 데이터)</b>로 불러올 때 사용하는 <b>pandas</b> 함수이다. 설문조사 데이터에서 자주 사용되는 파일 형식이며, 일반 텍스트 에디터로는 열리지 않는 것이 정상이다. Jupyter Notebook에서 SPSS 파일을 읽기 위해서는 `pyreadstat` 라이브러리를 설치해야 한다. 
            - (예: `uv add pyreadstat`)

* 만날 수 있는 에러: `FileNotFoundError` , `UnicodeDecodeError`, `ModuleNotFoundError`
    - `FileNotFoundError`: Jupyter Notebook에서 `read` 계열 메서드(`read_csv`, `read_excel` 등)로 파일을 불러올 때, 해당 파일을 찾지 못하면 발생한다. 주요 원인으론 파일 경로(Path) 오류, 파일 이름 오타, 그리고 파일이 실제로 해당 위치에 존하지 않을때 발생 한다.
    - `UnicodeDecodeError`: 맥(Mac) 운영체제는 기본적으로 <b>UTF-8</b> 인코딩을 사용하고, 윈도우(Windows) 운영체제는 <b>CP949(또는 EUC-KR)</b> 인코딩을 많이 사용한다. 다른 운영체제에서 저장한 파일을 그대로 열면 문자 인코딩 방식이 맞지 않아 이 에러가 발생할 수 있다.
    - `ModuleNotFoundError`: 코드에서 `import` 하려는 모듈(라이브러리)이 설치되어 있지 않을 때 발생한다. 주요 원인으론 필요한 패키지가 설치되지 않거나 가상환경과 실제 설치 위기가 다를때 발생 한다/

## 2. 데이터 정보 확인

* 데이터 속성: `data.columns`, `data.shape`
    - `data.columns`: 데이터프레임의 열(column) 이름들을 확인할 때 사용한다. 필요하다면 열 이름을 직접 지정하거나 수정할 수도 있다.
    - `data.shape`: 데이터프레임의 행(row) 수와 열(column) 수를 튜플로 반환한다. 
        - 예: <b>(행 개수, 열 개수)</b>
* 데이터 전체 정보: `data.info()`
    - `data.info`: <b>Pandas</b>의 <b>DataFrame</b>에 주로 사용하는 메서드로, 데이터의 요약 정보를 보여준다.요약 정보에는 <b>행(row) 수</b>, <b>열(column) 수</b>, 각 <b>열의 데이터 타입(dtype)</b>, 각 <b>열의 결측치(null) 개수</b>, <b>메모리 사용량</b>이 포함된다. 참고로  <b>Series</b> 객체에는 `info()` 메서드가 없다. 
* 데이터 형 변환: `data.astype()`, `pd.to_datetime()`
    - `data.astype()`: 특정 열의 데이터 타입을 원하는 타입으로 변경할 때 사용한다. 다만, 날짜형으로 직접 변환할 수는 없다.
    - `pd.to_datetime()`: 문자열이나 다른 타입의 데이터를 <b>날짜형(datetime)</b> 으로 변환할 때 사용한다.
* 범주형 변수 카테고리 조회: `data.unique()`, `data.describe()`
    - `data.unique()`: 해당 열에서 <b>`중복을 제거한 고유한 값들만 모아 반환</b>한다.
    - `data.describe()`: 데이터의 <b>통계 요약</b>을 보여준다. 기본적으로 수치형 컬럼에 대해 <b>count</b>, <b>mean</b>, <b>std</b>, <b>min</b>, <b>25%</b>, <b>50%</b>, <b>75%</b>, <b>max</b> 값을 계산해 준다. 문자형 컬럼은 기본적으로 제외되지만, `include` 옵션으로 데이터 타입을 지정하면 통계 요약에 포함시킬 수 있다.
        - 예: `data.describe(include='all')` → 문자열 컬럼까지 포함하여 요약


    데이터 내용의 통계 요약을 보여주는데 기본적으로 수치형 컬럼에 대해 count, mean, std, min, 25%, 50%, 75%, max 값을 계산해서 보여준다. 문자형 컬럼은 기본적으로 통계 요약에서 제외 되며 `include`옵션으로 특정 데이터 타입을 통계낼수 있으며 `include=all`으로 지정시 문자열도 통계에서 볼수 있다.
* 연속형 변수 요약: `data.describe()`
    - `data.describe()`:

## 3. 결측치 처리

* 결측치 개수 파악: `data.isna()`, `data.isnull()`
    - `data.isna()`: 데이터에 <b>결측치(Missing Value)</b> 가 있는지 판단하기 위한 메서드이다. 각 셀별로 결측치 여부를 <b>Boolean 값(True/False)</b> 으로 반환한다.
    - `data.isnull()`: `isna()`와 기능이 동일하며, 데이터가 <b>결측치(null)</b>인지 여부를 확인할 때 사용한다.
* 결측치 처리: `data.fillna()`, `data.dropna(subset=[])`
    - `data.fillna(n)`: <b>결측치(Missing Value)</b>를 지정한 값 <b>n</b>으로 채운다.
    - `data.dropna(subset=[])`: 결측치가 포함된 행 또는 열을 제거한다.`subset` param에 특정 열 이름들을 지정하면, 해당 열들에서 결측치가 있는 행만 제거한다.

## 4. 데이터 시각화 

### 1) 변수 분포 파악

* 범주형/순서형/이산형: 막대그래프
    - 범주형: 정해진 그룹 중 하나이고 순서는없다.
        - 예) 성별, 지역, 브랜드
    - 순서형: 정해진 순서는 있으며 간격은 일정하지 않다.
        - 예) 만족도(상중하), 학점, 등급(상/중/하)
    - 이산형: 개수 등 정수로 표현, 셀 수 있다.
        - 예) 자녀 수, 구매 횟수, 건수, 횟수
* 연속형: 히스토그램, 상자그림
    - 연속형: 소수 포함, 정리한 수치, 간격의미가 있다.
        - 예) 키, 몸무게, 수입, 나이, 점수
* 시계열: 선그래프
    - 시간 흐름에 따라 측정된다.
        - 예) 일별 기온, 주간 매출, 일자별 매출, 월별 평균값
* 전처리가 필요한가? ex. 이상치 제거, 로그 변환 등
    - 실제 데이터는 그대로 분석하기 어려운 경우가 많기 때문에, 정확한 분석과 올바른 시각화를 위해 반드시 필요한 단계이다. 이상치 제거, 결측치 처리, 분포 개선(로그 변환 등), 타입 변환, 중복 제거 같은 과정을 통해 데이터 품질을 높이고 신뢰할 수 있는 분석 결과를 얻을 수 있다. 
    - <b>이상치(Outlier 제거)</b>
        - <b>필요성</b>: 극단적인 값이 포함되어 있으면 평균이나 분산 등의 통계량이 왜곡되고, 시각화 결과도 비정상적으로 보일 수 있다.
        - <b>예시</b>: 월급 데이터에서 1명만 100억을 받는다면 평균이 실제보다 크게 나옴.
    - <b>결측치(Missing Value)처리</b>
        - <b>필요성</b>: 결측치가 있으면 분석이나 그래프 그리기 과정에서 오류가 발생하거나, 계산 결과가 왜곡될 수 있다.
        - <b>방법</b>: 결측치 데이터를 삭제하거나. 평균/중앙값/최반값으로 대체(fill)하면 된다.
    - <b>데이터 분포 개선</b>
        - <b>필요성</b>: 값의 범위가 너무 크거나 한쪽으로 치우쳐 있으면, 그래프 해석이 어렵거나 모델링 성능이 떨어질 수 있다.
        - <b>방법</b>: 로그 변환과 제곱근 변환 등으로 분포를 완화할수 있고 정규화/표준화로 스케일 맞출수 있다.
    - <b>형식 통일 및 타입 변환</b>
        - <b>필요성</b>: 날짜, 문자, 숫자 등 데이터 타입이 제각각이면 연산이 불가능하거나 오류 발생한다.
        - <b>방법</b>: `pd.to_datetime()`으로 날짜형 변환과 문자열 처리 및 정리를 한다.
    - <b>중복값 제거</b>
        - 동일한 행이 여러 번 포함돼 있으면 분석 결과가 왜곡된다.     


### 2) 변수 관계 파악

* `data.groupby()`, `pd.pivot_table()`, `pd.crosstab()`
    - `data.groupby()`: 특정 열을 기준으로 데이터를 그룹화하여 집계(합계, 평균 등)할 수 있다.
        - 예) `data.groupby('지역')['매출'].mean()`
    - `pd.pivot_table()`: 피벗 테이블을 만들어 다차원 데이터를 요약·집계할 수 있다. 행과 열을 기준으로 원하는 집계를 적용할 수 있다.
    - `pd.crosstab()`: 두 범주형 변수 간의 교차 빈도표를 만든다.
* 상관관계: `data.corr()`, `sns.pairplot()`, `sns.heatmap()`
    - `data.corr()`: DataFrame의 수치형 열들 간 상관계수를 계산한다. 
    - `sns.pairplot()`: 변수들 간의 산점도와 히스토그램을 한눈에 보여준다. 상관성을 시각적으로 파악하기 좋다.
    - `sns.heatmap()`: 상관계수 행렬 등을 색상으로 시각화한다.


## 7. 결론

* 어떤 전처리를 진행했나요?
    - 결측치를 `dropna()`로 제거 할거나 `fillna()`로 평균값 채우기
    - Boxplot으로 이상치 확인후 제거하기
    - 문자열 날짜를 `pd.to_datetime()`으로 변환하하기
    - 중복 데이터를 `data.drop_duplicate()`로 제거하기
    - 필요한 열만 선택하거나 대소문자 이름 정리하기
    - 데이터 값의 분포가 한쪽으로 치우쳐 있을 때 로그 변환하기
        - 예) `data['매출'] = np.log1p(data['매출'])`
    
- 데이터의 특징이 무엇인가요?
    - <b>행(row)</b> 수와 <b>열(column)</b>수로 되어있다.
    - 데이터는 범주형, 연속형, 순서형, 이산형, 시계열, 텍스트. 그리고 위치정보형 유형이 있다.